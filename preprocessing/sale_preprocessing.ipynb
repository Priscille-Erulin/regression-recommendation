{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_log(train: pd.DataFrame, columns_to_log: list):\n",
    "    \"\"\" \n",
    "    Adding columns using log of provided information.\n",
    "    \"\"\"\n",
    "    new_train = train.__deepcopy__()\n",
    "    for column_name in columns_to_log:\n",
    "        new_position = train.columns.get_loc(str(column_name)) + 1\n",
    "        new_name = str ('log_' + str(column_name))\n",
    "        new_train.insert(new_position, new_name, np.log(new_train[str(column_name)] + 1))\n",
    "        new_train = new_train.drop(str(column_name), axis='columns')\n",
    "        \n",
    "    return (new_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df, scaler, numerical_columns: list):\n",
    "    \"\"\"\n",
    "    Returns dataframe with the given columns scaled.\n",
    "    \"\"\"\n",
    "    new_train = df.__deepcopy__()\n",
    "    num_train_data = new_train[numerical_columns]\n",
    "    new_train[numerical_columns] = scaler.transform(num_train_data)\n",
    "\n",
    "    return (new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_pre_pocessing(all_sales, cols_to_log, scaler, cols_to_scale):\n",
    "\n",
    "    dummies_category = pd.get_dummies(all_sales['Category'])\n",
    "    dummies_badges = all_sales['Badges'].str.strip('{}').str.replace('\"', '').str.get_dummies(',')\n",
    "    dropped_cols_sales = all_sales.drop(['Category','Badges'], axis = 1)\n",
    "\n",
    "    all_sales_dummies = pd.concat([dropped_cols_sales, dummies_category, dummies_badges], axis = 1)\n",
    "\n",
    "    all_sales_logged = adding_log(all_sales_dummies, cols_to_log)\n",
    "\n",
    "    all_sales_scaled = scale(all_sales_logged, scaler, cols_to_scale,)\n",
    "    \n",
    "    return all_sales_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['log_Followers',\n",
    "               'log_Avg Price',\n",
    "               'log_First Day Revenue',\n",
    "               'log_Brand Appearance',\n",
    "               'Avg Discount',\n",
    "               'Conversion']\n",
    "\n",
    "log_columns = ['Followers', 'Avg Price', 'First Day Revenue', 'Brand Appearance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('scaler_numerical.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sales = pd.read_csv('sales_jan23_avr23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sales = sales_pre_pocessing(all_sales, log_columns, scaler, num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sales.to_csv('pp_sales_jan23_avr23.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
