{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNNS_FOR_ML = ['log_delta','log_followers','conversion',\n",
    "                   'log_revenue','log_brand_appearance','log_avg_price',\n",
    "                   'artisanal', 'b_corporation', 'bio', 'biodegradable',\n",
    "                   'cadeau_ideal', 'concept_original', 'durable',\n",
    "                   'eco_friendly','excellent_sur_yuka', 'exclusivite_choose',\n",
    "                   'fabrication_a_la_demande', 'fait_main', 'gluten_free',\n",
    "                   'iconique', 'inclusive', 'innovation', 'made_in_europe',\n",
    "                   'made_in_france', 'madeinjapan', 'naturel', 'oeko_tex',\n",
    "                   'premium', 'recyclable', 'saint_valentin', 'savoir_faire',\n",
    "                   'seconde_main', 'socialement_engagee', 'serie_limitee',\n",
    "                   'tendance', 'upcycling', 'vegan', 'vintage', 'zerodechet',\n",
    "                   'category_sale',\n",
    "                   'log_monetary', 'log_frequency','log_recency',\n",
    "                   'category_1','category_2', 'category_3'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_test_data = pd.read_csv('training_preparation/preped_test_data.csv', index_col=0).dropna().reset_index(drop=True)\n",
    "scored_train_data = pd.read_csv('training_preparation/preped_train_data.csv', index_col=0).dropna().reset_index(drop=True)\n",
    "all_scored_data = pd.concat([scored_test_data,scored_train_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scored_train_data[COLUMNNS_FOR_ML].values\n",
    "y_train = scored_train_data['interaction']\n",
    "Y_train = np.ravel(y_train)\n",
    "\n",
    "X_total = all_scored_data[COLUMNNS_FOR_ML].values\n",
    "y_total = all_scored_data['interaction']\n",
    "\n",
    "X_test = scored_test_data[COLUMNNS_FOR_ML].values\n",
    "y_test = scored_test_data['interaction']\n",
    "Y_test = np.ravel(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "def gs_regression(model, par) :\n",
    "    gs = GridSearchCV(model, par,cv=3,scoring ='neg_mean_absolute_error', verbose=10) \n",
    "    gs = gs.fit(X_train,y_train)\n",
    "\n",
    "    #summarize the results of your GRIDSEARCH\n",
    "    print('***GRIDSEARCH RESULTS***')\n",
    "    print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    params = gs.cv_results_['params']\n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "    #    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    y_pred_train=gs.predict(X_train)\n",
    "    y_pred_test=gs.predict(X_test) \n",
    "    \n",
    "    y_train_exp=y_train.apply(lambda x: math.exp(x)-1)\n",
    "    y_test_exp=y_test.apply(lambda x: math.exp(x)-1)\n",
    "    y_pred_train_exp=np.exp(y_pred_train)-1\n",
    "    y_pred_test_exp=np.exp(y_pred_test)-1\n",
    "    \n",
    "            \n",
    "    from sklearn import metrics\n",
    "    print()\n",
    "    print(\"MAE  train %.3f (%f)  test %.3f (%f)\" % (metrics.mean_absolute_error(y_train, y_pred_train), metrics.mean_absolute_error(y_train_exp, y_pred_train_exp) ,metrics.mean_absolute_error(y_test, y_pred_test),  metrics.mean_absolute_error(y_test_exp, y_pred_test_exp)  ) )\n",
    "    print(\"MSE  train %.3f              test %.3f\" % (metrics.mean_squared_error(y_train, y_pred_train), metrics.mean_squared_error(y_test, y_pred_test)) ) \n",
    "    print(\"RMSE train %.3f              test %.3f\" % (np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))) ) \n",
    "    print(\"r2   train %.3f              test %.3f\" % (metrics.r2_score(y_train, y_pred_train), metrics.r2_score(y_test, y_pred_test)) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3; 1/1] START ............................................................\n",
      "[CV 1/3; 1/1] END ............................., score=-0.421 total time=   2.5s\n",
      "[CV 2/3; 1/1] START ............................................................\n",
      "[CV 2/3; 1/1] END ............................., score=-0.421 total time=   2.6s\n",
      "[CV 3/3; 1/1] START ............................................................\n",
      "[CV 3/3; 1/1] END ............................., score=-0.421 total time=   3.3s\n",
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.420915 using {}\n",
      "\n",
      "MAE  train 0.421 (0.729379)  test 0.424 (0.728327)\n",
      "MSE  train 0.209              test 0.210\n",
      "RMSE train 0.457              test 0.459\n",
      "r2   train 0.163              test 0.159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression() \n",
    "parameters = {}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #Ordinary Least Squares\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(regr, open('regr_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3; 1/5] START alpha=0.001.................................................\n",
      "[CV 1/3; 1/5] END .................alpha=0.001;, score=-0.416 total time=   0.3s\n",
      "[CV 2/3; 1/5] START alpha=0.001.................................................\n",
      "[CV 2/3; 1/5] END .................alpha=0.001;, score=-0.416 total time=   0.3s\n",
      "[CV 3/3; 1/5] START alpha=0.001.................................................\n",
      "[CV 3/3; 1/5] END .................alpha=0.001;, score=-0.416 total time=   0.3s\n",
      "[CV 1/3; 2/5] START alpha=0.01..................................................\n",
      "[CV 1/3; 2/5] END ..................alpha=0.01;, score=-0.416 total time=   0.4s\n",
      "[CV 2/3; 2/5] START alpha=0.01..................................................\n",
      "[CV 2/3; 2/5] END ..................alpha=0.01;, score=-0.416 total time=   0.5s\n",
      "[CV 3/3; 2/5] START alpha=0.01..................................................\n",
      "[CV 3/3; 2/5] END ..................alpha=0.01;, score=-0.416 total time=   0.4s\n",
      "[CV 1/3; 3/5] START alpha=0.1...................................................\n",
      "[CV 1/3; 3/5] END ...................alpha=0.1;, score=-0.416 total time=   0.5s\n",
      "[CV 2/3; 3/5] START alpha=0.1...................................................\n",
      "[CV 2/3; 3/5] END ...................alpha=0.1;, score=-0.416 total time=   0.5s\n",
      "[CV 3/3; 3/5] START alpha=0.1...................................................\n",
      "[CV 3/3; 3/5] END ...................alpha=0.1;, score=-0.416 total time=   0.4s\n",
      "[CV 1/3; 4/5] START alpha=1.....................................................\n",
      "[CV 1/3; 4/5] END .....................alpha=1;, score=-0.416 total time=   0.4s\n",
      "[CV 2/3; 4/5] START alpha=1.....................................................\n",
      "[CV 2/3; 4/5] END .....................alpha=1;, score=-0.416 total time=   0.3s\n",
      "[CV 3/3; 4/5] START alpha=1.....................................................\n",
      "[CV 3/3; 4/5] END .....................alpha=1;, score=-0.416 total time=   0.7s\n",
      "[CV 1/3; 5/5] START alpha=10....................................................\n",
      "[CV 1/3; 5/5] END ....................alpha=10;, score=-0.416 total time=   0.7s\n",
      "[CV 2/3; 5/5] START alpha=10....................................................\n",
      "[CV 2/3; 5/5] END ....................alpha=10;, score=-0.416 total time=   0.4s\n",
      "[CV 3/3; 5/5] START alpha=10....................................................\n",
      "[CV 3/3; 5/5] END ....................alpha=10;, score=-0.416 total time=   0.5s\n",
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.416235 using {'alpha': 0.001}\n",
      "\n",
      "MAE  train 0.416 (0.737498)  test 0.420 (0.741187)\n",
      "MSE  train 0.207              test 0.213\n",
      "RMSE train 0.455              test 0.461\n",
      "r2   train 0.162              test 0.137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "regressor = Ridge()\n",
    "parameters = {\"alpha\": [0.001,0.01,0.1,1,10]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.001)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.001)\n",
    "# Train the model using the training sets\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ridge, open('ridge_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3; 1/4] START alpha=0.001.................................................\n",
      "[CV 1/3; 1/4] END .................alpha=0.001;, score=-0.424 total time=   1.5s\n",
      "[CV 2/3; 1/4] START alpha=0.001.................................................\n",
      "[CV 2/3; 1/4] END .................alpha=0.001;, score=-0.424 total time=   1.3s\n",
      "[CV 3/3; 1/4] START alpha=0.001.................................................\n",
      "[CV 3/3; 1/4] END .................alpha=0.001;, score=-0.424 total time=   1.1s\n",
      "[CV 1/3; 2/4] START alpha=0.002.................................................\n",
      "[CV 1/3; 2/4] END .................alpha=0.002;, score=-0.424 total time=   1.2s\n",
      "[CV 2/3; 2/4] START alpha=0.002.................................................\n",
      "[CV 2/3; 2/4] END .................alpha=0.002;, score=-0.425 total time=   1.1s\n",
      "[CV 3/3; 2/4] START alpha=0.002.................................................\n",
      "[CV 3/3; 2/4] END .................alpha=0.002;, score=-0.424 total time=   1.1s\n",
      "[CV 1/3; 3/4] START alpha=0.005.................................................\n",
      "[CV 1/3; 3/4] END .................alpha=0.005;, score=-0.426 total time=   1.0s\n",
      "[CV 2/3; 3/4] START alpha=0.005.................................................\n",
      "[CV 2/3; 3/4] END .................alpha=0.005;, score=-0.426 total time=   1.2s\n",
      "[CV 3/3; 3/4] START alpha=0.005.................................................\n",
      "[CV 3/3; 3/4] END .................alpha=0.005;, score=-0.426 total time=   1.1s\n",
      "[CV 1/3; 4/4] START alpha=0.007.................................................\n",
      "[CV 1/3; 4/4] END .................alpha=0.007;, score=-0.427 total time=   1.1s\n",
      "[CV 2/3; 4/4] START alpha=0.007.................................................\n",
      "[CV 2/3; 4/4] END .................alpha=0.007;, score=-0.427 total time=   1.2s\n",
      "[CV 3/3; 4/4] START alpha=0.007.................................................\n",
      "[CV 3/3; 4/4] END .................alpha=0.007;, score=-0.427 total time=   1.2s\n",
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.423810 using {'alpha': 0.001}\n",
      "\n",
      "MAE  train 0.424 (0.735193)  test 0.425 (0.731528)\n",
      "MSE  train 0.210              test 0.212\n",
      "RMSE train 0.458              test 0.460\n",
      "r2   train 0.160              test 0.154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "regressor = Lasso()\n",
    "parameters = {\"alpha\": [0.001,0.002,0.005,0.007]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.001)\n",
    "# Train the model using the training sets\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lasso, open('lasso_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV 1/3; 1/6] START n_neighbors=20, p=1.........................................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "regressor = KNeighborsRegressor()\n",
    "\n",
    "parameters = {'n_neighbors': np.arange(20,50,10),\n",
    "              'p': [1,2]\n",
    "            }\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 1/3; 1/3] START criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/3] END criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42;, score=-0.364 total time=12.7min\n",
      "[CV 2/3; 1/3] START criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 1/3] END criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42;, score=-0.364 total time=200.3min\n",
      "[CV 3/3; 1/3] START criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/3] END criterion=mse, min_samples_leaf=5, n_estimators=100, random_state=42;, score=-0.365 total time=213.4min\n",
      "[CV 1/3; 2/3] START criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 2/3] END criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42;, score=-0.367 total time=166.6min\n",
      "[CV 2/3; 2/3] START criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 2/3] END criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42;, score=-0.367 total time=205.6min\n",
      "[CV 3/3; 2/3] START criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 2/3] END criterion=mse, min_samples_leaf=10, n_estimators=100, random_state=42;, score=-0.367 total time=151.5min\n",
      "[CV 1/3; 3/3] START criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/3] END criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42;, score=-0.369 total time=19.7min\n",
      "[CV 2/3; 3/3] START criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 3/3] END criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42;, score=-0.369 total time=12.0min\n",
      "[CV 3/3; 3/3] START criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 3/3] END criterion=mse, min_samples_leaf=15, n_estimators=100, random_state=42;, score=-0.370 total time=12.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.364455 using {'criterion': 'mse', 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "\n",
      "MAE  train 0.288 (0.508912)  test 0.415 (0.721468)\n",
      "MSE  train 0.119              test 0.205\n",
      "RMSE train 0.345              test 0.453\n",
      "r2   train 0.524              test 0.181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "parameters = {\"n_estimators\":[100], \"criterion\": ['mse'], \n",
    "              \"min_samples_leaf\": [5,10,15], \"random_state\" : [42]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='mse', min_samples_leaf=5, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "RFR = RandomForestRegressor(criterion= 'mse', min_samples_leaf= 5, n_estimators= 100, random_state= 42)\n",
    "RFR.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(RFR, open('RFR_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support verctor regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3; 1/24] START C=0.1, degree=2, epsilon=0.01, gamma=auto, kernel=linear...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "regressor = SVR()\n",
    "parameters = {'C': [0.1,10,1000],\n",
    "             'epsilon': [0.01,1],\n",
    "             'gamma':['auto'],\n",
    "             'kernel': ['linear','poly'],\n",
    "             'degree': [2,3]\n",
    "             }\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r8/txzynl1j0xj6xzvf7622s2vw0000gn/T/ipykernel_1920/588225610.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_total' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(C=0.1, epsilon=0.01, gamma='auto')\n",
    "svr.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svr, open('svr_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV 1/3; 1/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 1/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.417 total time= 2.9min\n",
      "[CV 2/3; 1/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 1/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.418 total time= 2.8min\n",
      "[CV 3/3; 1/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 1/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.416 total time= 2.7min\n",
      "[CV 1/3; 2/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 2/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.418 total time= 2.5min\n",
      "[CV 2/3; 2/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 2/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.415 total time= 2.5min\n",
      "[CV 3/3; 2/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 2/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.415 total time= 2.7min\n",
      "[CV 1/3; 3/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 3/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.416 total time= 2.3min\n",
      "[CV 2/3; 3/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 3/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.421 total time= 2.3min\n",
      "[CV 3/3; 3/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 3/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.422 total time= 2.2min\n",
      "[CV 1/3; 4/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 4/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.416 total time= 2.3min\n",
      "[CV 2/3; 4/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 4/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.421 total time= 2.2min\n",
      "[CV 3/3; 4/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 4/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 5, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.422 total time= 2.3min\n",
      "[CV 1/3; 5/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 5/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.417 total time= 2.2min\n",
      "[CV 2/3; 5/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 5/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.413 total time= 2.2min\n",
      "[CV 3/3; 5/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 5/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 10, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.413 total time= 2.2min\n",
      "[CV 1/3; 6/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 6/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.418 total time= 2.1min\n",
      "[CV 2/3; 6/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 6/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.414 total time= 2.2min\n",
      "[CV 3/3; 6/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 6/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.415 total time= 2.2min\n",
      "[CV 1/3; 7/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 1/3; 7/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.414 total time= 1.8min\n",
      "[CV 2/3; 7/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 2/3; 7/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.417 total time= 1.8min\n",
      "[CV 3/3; 7/7] START alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd\n",
      "[CV 3/3; 7/7] END alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 5, 5), learning_rate=constant, max_iter=10000, solver=sgd;, score=-0.422 total time= 1.8min\n",
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.414456 using {'alpha': 0.1, 'batch_size': 20, 'hidden_layer_sizes': (20, 10, 10, 10), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'sgd'}\n",
      "\n",
      "MAE  train 0.413 (0.723382)  test 0.417 (0.726989)\n",
      "MSE  train 0.209              test 0.208\n",
      "RMSE train 0.457              test 0.456\n",
      "r2   train 0.163              test 0.167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regressor = MLPRegressor(random_state=0)\n",
    "parameters = {'hidden_layer_sizes': [(20, 20, 20, 10, 10),(20, 20, 10, 10, 10),(20,10,5,10), (20,10,5,10), (20,10,10,10),(20,20,10,10), (20,5,5)],\n",
    "              'solver' : ['sgd'],\n",
    "              'batch_size': [20],\n",
    "              'learning_rate' : ['constant'],\n",
    "              'alpha':[0.1],\n",
    "              'max_iter':[10000]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.1, batch_size=20, hidden_layer_sizes=(20, 20, 10, 10),\n",
       "             max_iter=10000, solver='sgd')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "MLPR = MLPRegressor(alpha= 0.1, batch_size=20, hidden_layer_sizes= (20, 20, 10, 10), max_iter= 10000, solver= 'sgd')\n",
    "MLPR.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(MLPR, open('MLPR_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3; 1/16] START learning_rate=0.2, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 1/3; 1/16] END learning_rate=0.2, loss=linear, n_estimators=5, random_state=0;, score=-0.422 total time=  20.1s\n",
      "[CV 2/3; 1/16] START learning_rate=0.2, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 2/3; 1/16] END learning_rate=0.2, loss=linear, n_estimators=5, random_state=0;, score=-0.422 total time=  18.6s\n",
      "[CV 3/3; 1/16] START learning_rate=0.2, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 3/3; 1/16] END learning_rate=0.2, loss=linear, n_estimators=5, random_state=0;, score=-0.423 total time=  19.6s\n",
      "[CV 1/3; 2/16] START learning_rate=0.2, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 1/3; 2/16] END learning_rate=0.2, loss=linear, n_estimators=10, random_state=0;, score=-0.423 total time=  35.6s\n",
      "[CV 2/3; 2/16] START learning_rate=0.2, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 2/3; 2/16] END learning_rate=0.2, loss=linear, n_estimators=10, random_state=0;, score=-0.423 total time=  35.1s\n",
      "[CV 3/3; 2/16] START learning_rate=0.2, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 3/3; 2/16] END learning_rate=0.2, loss=linear, n_estimators=10, random_state=0;, score=-0.424 total time=  35.2s\n",
      "[CV 1/3; 3/16] START learning_rate=0.2, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 1/3; 3/16] END learning_rate=0.2, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=  45.4s\n",
      "[CV 2/3; 3/16] START learning_rate=0.2, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 2/3; 3/16] END learning_rate=0.2, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=  52.7s\n",
      "[CV 3/3; 3/16] START learning_rate=0.2, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 3/3; 3/16] END learning_rate=0.2, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=22.6min\n",
      "[CV 1/3; 4/16] START learning_rate=0.2, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 1/3; 4/16] END learning_rate=0.2, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time=11.6min\n",
      "[CV 2/3; 4/16] START learning_rate=0.2, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 2/3; 4/16] END learning_rate=0.2, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time=  52.0s\n",
      "[CV 3/3; 4/16] START learning_rate=0.2, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 3/3; 4/16] END learning_rate=0.2, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time= 1.1min\n",
      "[CV 1/3; 5/16] START learning_rate=0.1, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 1/3; 5/16] END learning_rate=0.1, loss=linear, n_estimators=5, random_state=0;, score=-0.422 total time=  23.7s\n",
      "[CV 2/3; 5/16] START learning_rate=0.1, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 2/3; 5/16] END learning_rate=0.1, loss=linear, n_estimators=5, random_state=0;, score=-0.422 total time=  21.0s\n",
      "[CV 3/3; 5/16] START learning_rate=0.1, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 3/3; 5/16] END learning_rate=0.1, loss=linear, n_estimators=5, random_state=0;, score=-0.423 total time=  23.5s\n",
      "[CV 1/3; 6/16] START learning_rate=0.1, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 1/3; 6/16] END learning_rate=0.1, loss=linear, n_estimators=10, random_state=0;, score=-0.422 total time=  44.3s\n",
      "[CV 2/3; 6/16] START learning_rate=0.1, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 2/3; 6/16] END learning_rate=0.1, loss=linear, n_estimators=10, random_state=0;, score=-0.423 total time=  40.5s\n",
      "[CV 3/3; 6/16] START learning_rate=0.1, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 3/3; 6/16] END learning_rate=0.1, loss=linear, n_estimators=10, random_state=0;, score=-0.423 total time=  41.0s\n",
      "[CV 1/3; 7/16] START learning_rate=0.1, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 1/3; 7/16] END learning_rate=0.1, loss=linear, n_estimators=20, random_state=0;, score=-0.422 total time= 1.4min\n",
      "[CV 2/3; 7/16] START learning_rate=0.1, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 2/3; 7/16] END learning_rate=0.1, loss=linear, n_estimators=20, random_state=0;, score=-0.423 total time= 1.4min\n",
      "[CV 3/3; 7/16] START learning_rate=0.1, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 3/3; 7/16] END learning_rate=0.1, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time= 1.4min\n",
      "[CV 1/3; 8/16] START learning_rate=0.1, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 1/3; 8/16] END learning_rate=0.1, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time= 2.4min\n",
      "[CV 2/3; 8/16] START learning_rate=0.1, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 2/3; 8/16] END learning_rate=0.1, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time= 2.1min\n",
      "[CV 3/3; 8/16] START learning_rate=0.1, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 3/3; 8/16] END learning_rate=0.1, loss=linear, n_estimators=30, random_state=0;, score=-0.425 total time= 1.9min\n",
      "[CV 1/3; 9/16] START learning_rate=0.5, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 1/3; 9/16] END learning_rate=0.5, loss=linear, n_estimators=5, random_state=0;, score=-0.425 total time=  22.2s\n",
      "[CV 2/3; 9/16] START learning_rate=0.5, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 2/3; 9/16] END learning_rate=0.5, loss=linear, n_estimators=5, random_state=0;, score=-0.423 total time=  24.7s\n",
      "[CV 3/3; 9/16] START learning_rate=0.5, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 3/3; 9/16] END learning_rate=0.5, loss=linear, n_estimators=5, random_state=0;, score=-0.423 total time=  25.4s\n",
      "[CV 1/3; 10/16] START learning_rate=0.5, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 1/3; 10/16] END learning_rate=0.5, loss=linear, n_estimators=10, random_state=0;, score=-0.425 total time=  28.3s\n",
      "[CV 2/3; 10/16] START learning_rate=0.5, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 2/3; 10/16] END learning_rate=0.5, loss=linear, n_estimators=10, random_state=0;, score=-0.424 total time=  41.2s\n",
      "[CV 3/3; 10/16] START learning_rate=0.5, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 3/3; 10/16] END learning_rate=0.5, loss=linear, n_estimators=10, random_state=0;, score=-0.426 total time=  34.2s\n",
      "[CV 1/3; 11/16] START learning_rate=0.5, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 1/3; 11/16] END learning_rate=0.5, loss=linear, n_estimators=20, random_state=0;, score=-0.425 total time=  26.2s\n",
      "[CV 2/3; 11/16] START learning_rate=0.5, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 2/3; 11/16] END learning_rate=0.5, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=  37.8s\n",
      "[CV 3/3; 11/16] START learning_rate=0.5, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 3/3; 11/16] END learning_rate=0.5, loss=linear, n_estimators=20, random_state=0;, score=-0.426 total time=  35.0s\n",
      "[CV 1/3; 12/16] START learning_rate=0.5, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 1/3; 12/16] END learning_rate=0.5, loss=linear, n_estimators=30, random_state=0;, score=-0.425 total time=  30.2s\n",
      "[CV 2/3; 12/16] START learning_rate=0.5, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 2/3; 12/16] END learning_rate=0.5, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time=  39.1s\n",
      "[CV 3/3; 12/16] START learning_rate=0.5, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 3/3; 12/16] END learning_rate=0.5, loss=linear, n_estimators=30, random_state=0;, score=-0.426 total time=  36.2s\n",
      "[CV 1/3; 13/16] START learning_rate=0.3, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 1/3; 13/16] END learning_rate=0.3, loss=linear, n_estimators=5, random_state=0;, score=-0.422 total time=  18.0s\n",
      "[CV 2/3; 13/16] START learning_rate=0.3, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 2/3; 13/16] END learning_rate=0.3, loss=linear, n_estimators=5, random_state=0;, score=-0.423 total time=  17.2s\n",
      "[CV 3/3; 13/16] START learning_rate=0.3, loss=linear, n_estimators=5, random_state=0\n",
      "[CV 3/3; 13/16] END learning_rate=0.3, loss=linear, n_estimators=5, random_state=0;, score=-0.424 total time=  17.1s\n",
      "[CV 1/3; 14/16] START learning_rate=0.3, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 1/3; 14/16] END learning_rate=0.3, loss=linear, n_estimators=10, random_state=0;, score=-0.425 total time=  33.6s\n",
      "[CV 2/3; 14/16] START learning_rate=0.3, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 2/3; 14/16] END learning_rate=0.3, loss=linear, n_estimators=10, random_state=0;, score=-0.425 total time=  33.8s\n",
      "[CV 3/3; 14/16] START learning_rate=0.3, loss=linear, n_estimators=10, random_state=0\n",
      "[CV 3/3; 14/16] END learning_rate=0.3, loss=linear, n_estimators=10, random_state=0;, score=-0.424 total time=  27.1s\n",
      "[CV 1/3; 15/16] START learning_rate=0.3, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 1/3; 15/16] END learning_rate=0.3, loss=linear, n_estimators=20, random_state=0;, score=-0.425 total time=  43.5s\n",
      "[CV 2/3; 15/16] START learning_rate=0.3, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 2/3; 15/16] END learning_rate=0.3, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=  45.2s\n",
      "[CV 3/3; 15/16] START learning_rate=0.3, loss=linear, n_estimators=20, random_state=0\n",
      "[CV 3/3; 15/16] END learning_rate=0.3, loss=linear, n_estimators=20, random_state=0;, score=-0.424 total time=  27.6s\n",
      "[CV 1/3; 16/16] START learning_rate=0.3, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 1/3; 16/16] END learning_rate=0.3, loss=linear, n_estimators=30, random_state=0;, score=-0.425 total time=  45.1s\n",
      "[CV 2/3; 16/16] START learning_rate=0.3, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 2/3; 16/16] END learning_rate=0.3, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time=  45.4s\n",
      "[CV 3/3; 16/16] START learning_rate=0.3, loss=linear, n_estimators=30, random_state=0\n",
      "[CV 3/3; 16/16] END learning_rate=0.3, loss=linear, n_estimators=30, random_state=0;, score=-0.424 total time=  30.1s\n",
      "***GRIDSEARCH RESULTS***\n",
      "Best score: -0.422020 using {'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 5, 'random_state': 0}\n",
      "\n",
      "MAE  train 0.422 (0.733535)  test 0.429 (0.744396)\n",
      "MSE  train 0.211              test 0.214\n",
      "RMSE train 0.459              test 0.463\n",
      "r2   train 0.157              test 0.143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "regressor = AdaBoostRegressor() # base_estimator=DecisionTreeRegressor(max_depth=3)\n",
    "parameters = {\"n_estimators\":[5,10,20,30], \"learning_rate\":[0.2, 0.1,0.5,0.3], \n",
    "              \"loss\": ['linear'], \"random_state\" : [0]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(learning_rate=0.1, n_estimators=5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "Ada = AdaBoostRegressor(learning_rate= 0.1, loss='linear', n_estimators= 5)\n",
    "Ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Ada, open('ada_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3; 1/24] START learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 1/3; 1/24] END learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10;, score=-0.490 total time=  16.1s\n",
      "[CV 2/3; 1/24] START learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 2/3; 1/24] END learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10;, score=-0.490 total time=  18.2s\n",
      "[CV 3/3; 1/24] START learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 3/3; 1/24] END learning_rate=0.01, max_depth=1, n_estimators=20, random_state=10;, score=-0.490 total time=  16.1s\n",
      "[CV 1/3; 2/24] START learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 1/3; 2/24] END learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10;, score=-0.479 total time=  38.2s\n",
      "[CV 2/3; 2/24] START learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 2/3; 2/24] END learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10;, score=-0.479 total time=  38.4s\n",
      "[CV 3/3; 2/24] START learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 3/3; 2/24] END learning_rate=0.01, max_depth=1, n_estimators=50, random_state=10;, score=-0.479 total time=  39.1s\n",
      "[CV 1/3; 3/24] START learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 1/3; 3/24] END learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10;, score=-0.464 total time= 1.4min\n",
      "[CV 2/3; 3/24] START learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 2/3; 3/24] END learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10;, score=-0.464 total time= 1.3min\n",
      "[CV 3/3; 3/24] START learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 3/3; 3/24] END learning_rate=0.01, max_depth=1, n_estimators=100, random_state=10;, score=-0.464 total time= 1.3min\n",
      "[CV 1/3; 4/24] START learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 1/3; 4/24] END learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10;, score=-0.487 total time=  31.2s\n",
      "[CV 2/3; 4/24] START learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 2/3; 4/24] END learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10;, score=-0.487 total time=  32.2s\n",
      "[CV 3/3; 4/24] START learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 3/3; 4/24] END learning_rate=0.01, max_depth=2, n_estimators=20, random_state=10;, score=-0.487 total time=  32.2s\n",
      "[CV 1/3; 5/24] START learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 1/3; 5/24] END learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10;, score=-0.471 total time= 1.3min\n",
      "[CV 2/3; 5/24] START learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 2/3; 5/24] END learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10;, score=-0.471 total time= 1.3min\n",
      "[CV 3/3; 5/24] START learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 3/3; 5/24] END learning_rate=0.01, max_depth=2, n_estimators=50, random_state=10;, score=-0.471 total time= 1.3min\n",
      "[CV 1/3; 6/24] START learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 1/3; 6/24] END learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10;, score=-0.453 total time= 2.6min\n",
      "[CV 2/3; 6/24] START learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 2/3; 6/24] END learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10;, score=-0.453 total time= 2.5min\n",
      "[CV 3/3; 6/24] START learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 3/3; 6/24] END learning_rate=0.01, max_depth=2, n_estimators=100, random_state=10;, score=-0.453 total time= 2.6min\n",
      "[CV 1/3; 7/24] START learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 1/3; 7/24] END learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10;, score=-0.444 total time=  16.5s\n",
      "[CV 2/3; 7/24] START learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 2/3; 7/24] END learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10;, score=-0.444 total time=  16.4s\n",
      "[CV 3/3; 7/24] START learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 3/3; 7/24] END learning_rate=0.1, max_depth=1, n_estimators=20, random_state=10;, score=-0.444 total time=  16.7s\n",
      "[CV 1/3; 8/24] START learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 1/3; 8/24] END learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10;, score=-0.425 total time=  39.5s\n",
      "[CV 2/3; 8/24] START learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 2/3; 8/24] END learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10;, score=-0.425 total time=  38.9s\n",
      "[CV 3/3; 8/24] START learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 3/3; 8/24] END learning_rate=0.1, max_depth=1, n_estimators=50, random_state=10;, score=-0.425 total time=  38.7s\n",
      "[CV 1/3; 9/24] START learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 1/3; 9/24] END learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10;, score=-0.418 total time= 1.3min\n",
      "[CV 2/3; 9/24] START learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 2/3; 9/24] END learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10;, score=-0.418 total time= 1.3min\n",
      "[CV 3/3; 9/24] START learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 3/3; 9/24] END learning_rate=0.1, max_depth=1, n_estimators=100, random_state=10;, score=-0.419 total time= 1.3min\n",
      "[CV 1/3; 10/24] START learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 1/3; 10/24] END learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10;, score=-0.432 total time=  32.1s\n",
      "[CV 2/3; 10/24] START learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 2/3; 10/24] END learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10;, score=-0.432 total time=  31.6s\n",
      "[CV 3/3; 10/24] START learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 3/3; 10/24] END learning_rate=0.1, max_depth=2, n_estimators=20, random_state=10;, score=-0.432 total time=  30.6s\n",
      "[CV 1/3; 11/24] START learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 1/3; 11/24] END learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10;, score=-0.417 total time= 1.3min\n",
      "[CV 2/3; 11/24] START learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 2/3; 11/24] END learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10;, score=-0.417 total time= 1.3min\n",
      "[CV 3/3; 11/24] START learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 3/3; 11/24] END learning_rate=0.1, max_depth=2, n_estimators=50, random_state=10;, score=-0.417 total time= 1.3min\n",
      "[CV 1/3; 12/24] START learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 1/3; 12/24] END learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10;, score=-0.413 total time= 2.5min\n",
      "[CV 2/3; 12/24] START learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 2/3; 12/24] END learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10;, score=-0.413 total time= 2.5min\n",
      "[CV 3/3; 12/24] START learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 3/3; 12/24] END learning_rate=0.1, max_depth=2, n_estimators=100, random_state=10;, score=-0.414 total time= 7.9min\n",
      "[CV 1/3; 13/24] START learning_rate=1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 1/3; 13/24] END learning_rate=1, max_depth=1, n_estimators=20, random_state=10;, score=-0.416 total time=  17.0s\n",
      "[CV 2/3; 13/24] START learning_rate=1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 2/3; 13/24] END learning_rate=1, max_depth=1, n_estimators=20, random_state=10;, score=-0.416 total time=  17.0s\n",
      "[CV 3/3; 13/24] START learning_rate=1, max_depth=1, n_estimators=20, random_state=10\n",
      "[CV 3/3; 13/24] END learning_rate=1, max_depth=1, n_estimators=20, random_state=10;, score=-0.415 total time=  16.6s\n",
      "[CV 1/3; 14/24] START learning_rate=1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 1/3; 14/24] END learning_rate=1, max_depth=1, n_estimators=50, random_state=10;, score=-0.416 total time=  40.2s\n",
      "[CV 2/3; 14/24] START learning_rate=1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 2/3; 14/24] END learning_rate=1, max_depth=1, n_estimators=50, random_state=10;, score=-0.413 total time=  40.3s\n",
      "[CV 3/3; 14/24] START learning_rate=1, max_depth=1, n_estimators=50, random_state=10\n",
      "[CV 3/3; 14/24] END learning_rate=1, max_depth=1, n_estimators=50, random_state=10;, score=-0.414 total time=  40.8s\n",
      "[CV 1/3; 15/24] START learning_rate=1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 1/3; 15/24] END learning_rate=1, max_depth=1, n_estimators=100, random_state=10;, score=-0.413 total time= 1.3min\n",
      "[CV 2/3; 15/24] START learning_rate=1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 2/3; 15/24] END learning_rate=1, max_depth=1, n_estimators=100, random_state=10;, score=-0.414 total time= 1.3min\n",
      "[CV 3/3; 15/24] START learning_rate=1, max_depth=1, n_estimators=100, random_state=10\n",
      "[CV 3/3; 15/24] END learning_rate=1, max_depth=1, n_estimators=100, random_state=10;, score=-0.414 total time= 1.3min\n",
      "[CV 1/3; 16/24] START learning_rate=1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 1/3; 16/24] END learning_rate=1, max_depth=2, n_estimators=20, random_state=10;, score=-0.410 total time=  31.7s\n",
      "[CV 2/3; 16/24] START learning_rate=1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 2/3; 16/24] END learning_rate=1, max_depth=2, n_estimators=20, random_state=10;, score=-0.410 total time=  31.9s\n",
      "[CV 3/3; 16/24] START learning_rate=1, max_depth=2, n_estimators=20, random_state=10\n",
      "[CV 3/3; 16/24] END learning_rate=1, max_depth=2, n_estimators=20, random_state=10;, score=-0.411 total time=  31.5s\n",
      "[CV 1/3; 17/24] START learning_rate=1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 1/3; 17/24] END learning_rate=1, max_depth=2, n_estimators=50, random_state=10;, score=-0.403 total time= 1.3min\n",
      "[CV 2/3; 17/24] START learning_rate=1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 2/3; 17/24] END learning_rate=1, max_depth=2, n_estimators=50, random_state=10;, score=-0.404 total time= 1.3min\n",
      "[CV 3/3; 17/24] START learning_rate=1, max_depth=2, n_estimators=50, random_state=10\n",
      "[CV 3/3; 17/24] END learning_rate=1, max_depth=2, n_estimators=50, random_state=10;, score=-0.404 total time= 1.3min\n",
      "[CV 1/3; 18/24] START learning_rate=1, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 1/3; 18/24] END learning_rate=1, max_depth=2, n_estimators=100, random_state=10;, score=-0.400 total time= 3.4min\n",
      "[CV 2/3; 18/24] START learning_rate=1, max_depth=2, n_estimators=100, random_state=10\n",
      "[CV 2/3; 18/24] END learning_rate=1, max_depth=2, n_estimators=100, random_state=10;, score=-0.398 total time= 3.3min\n",
      "[CV 3/3; 18/24] START learning_rate=1, max_depth=2, n_estimators=100, random_state=10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor = GradientBoostingRegressor() \n",
    "parameters = {\"n_estimators\":[20,50,100], \"learning_rate\":[0.01, 0.1,1,10], \n",
    "              \"random_state\" : [10] ,\n",
    "             \"max_depth\":[1,2]}\n",
    "\n",
    "gs_regression(regressor, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1, max_depth=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBR = GradientBoostingRegressor(learning_rate=1, n_estimators=100, max_depth=2)\n",
    "GBR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(GBR, open('GBR_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(x_test, y_test)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "1875/1875 [==============================] - 2s 966us/step - loss: 0.7615 - accuracy: 0.7325\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.5279 - accuracy: 0.8149\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "1875/1875 [==============================] - 2s 718us/step - loss: 1.0020 - accuracy: 0.6643\n",
      "313/313 [==============================] - 0s 706us/step - loss: 0.6626 - accuracy: 0.7622\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8885 - accuracy: 0.6817\n",
      "313/313 [==============================] - 0s 891us/step - loss: 0.5517 - accuracy: 0.8065\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "1875/1875 [==============================] - 2s 758us/step - loss: 1.1287 - accuracy: 0.6070\n",
      "313/313 [==============================] - 0s 719us/step - loss: 0.6996 - accuracy: 0.7748\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6229 - accuracy: 0.7819\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8376\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "1875/1875 [==============================] - 2s 988us/step - loss: 0.8934 - accuracy: 0.6976\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.6179 - accuracy: 0.7928\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.6359 - accuracy: 0.7800\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8352\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.9537 - accuracy: 0.6803\n",
      "313/313 [==============================] - 0s 811us/step - loss: 0.6247 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "44738/66047 [===================>..........] - ETA: 20s - loss: 0.2125 - accuracy: 0.6669"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(X_train, Y_train, batch_size=20, epochs=15, validation_data=(X_test, Y_test))\n",
    "\n",
    "plt.plot(history1.history['loss'], marker='o', label='training loss')\n",
    "plt.plot(history1.history['val_loss'], marker='o', label='validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(0.2, 0.25)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.save('TF_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Feature conversion: 0.13033786416053772\n",
      "2. Feature log_revenue: 0.12142834812402725\n",
      "3. Feature log_avg_price: 0.04703013598918915\n",
      "4. Feature log_frequency: 0.04637593775987625\n",
      "5. Feature log_monetary: 0.04583758860826492\n",
      "6. Feature saint_valentin: 0.04387616738677025\n",
      "7. Feature innovation: 0.036797888576984406\n",
      "8. Feature oeko_tex: 0.03383103013038635\n",
      "9. Feature concept_original: 0.024469507858157158\n",
      "10. Feature premium: 0.02433004602789879\n",
      "11. Feature seconde_main: 0.02207506075501442\n",
      "12. Feature vegan: 0.020178072154521942\n",
      "13. Feature excellent_sur_yuka: 0.01981588453054428\n",
      "14. Feature biodegradable: 0.018985005095601082\n",
      "15. Feature tendance: 0.017507929354906082\n",
      "16. Feature inclusive: 0.017333930358290672\n",
      "17. Feature upcycling: 0.01619735360145569\n",
      "18. Feature exclusivite_choose: 0.016185613349080086\n",
      "19. Feature naturel: 0.01556459628045559\n",
      "20. Feature cadeau_ideal: 0.015101165510714054\n",
      "21. Feature vintage: 0.014050913974642754\n",
      "22. Feature iconique: 0.013366227969527245\n",
      "23. Feature fait_main: 0.013113772496581078\n",
      "24. Feature recyclable: 0.012973910197615623\n",
      "25. Feature madeinjapan: 0.012734207324683666\n",
      "26. Feature socialement_engagee: 0.011409621685743332\n",
      "27. Feature artisanal: 0.011120853014290333\n",
      "28. Feature b_corporation: 0.011006082408130169\n",
      "29. Feature durable: 0.010887116193771362\n",
      "30. Feature made_in_europe: 0.010850257240235806\n",
      "31. Feature category_3: 0.010662578046321869\n",
      "32. Feature made_in_france: 0.010275322012603283\n",
      "33. Feature log_recency: 0.010141213424503803\n",
      "34. Feature zerodechet: 0.00977008044719696\n",
      "35. Feature gluten_free: 0.008755060844123363\n",
      "36. Feature serie_limitee: 0.008535032160580158\n",
      "37. Feature bio: 0.008127781562507153\n",
      "38. Feature category_1: 0.008040431886911392\n",
      "39. Feature category_2: 0.0067801144905388355\n",
      "40. Feature eco_friendly: 0.006731422618031502\n",
      "41. Feature fabrication_a_la_demande: 0.006621810141950846\n",
      "42. Feature log_brand_appearance: 0.006236671004444361\n",
      "43. Feature category_sale: 0.005644854158163071\n",
      "44. Feature savoir_faire: 0.004944998305290937\n",
      "45. Feature log_followers: 0.004133970942348242\n",
      "46. Feature log_delta: 0.0038980329409241676\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('TF_model.h5')\n",
    "# Calculate the gradients of the model's output with respect to the input features\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    tape.watch(inputs)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "gradients = tape.gradient(outputs, inputs).numpy()\n",
    "\n",
    "# Calculate the feature importance as the mean absolute value of the gradients\n",
    "importances = np.mean(np.abs(gradients), axis=0)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print feature importance rankings\n",
    "for i, feature_idx in enumerate(indices):\n",
    "    print(f\"{i+1}. Feature {COLUMNNS_FOR_ML[feature_idx]}: {importances[feature_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
