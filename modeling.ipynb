{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_test_data = pd.read_csv('preped_test_data_wth_dummies.csv', index_col=0)\n",
    "score_train_data = pd.read_csv('preped_train_data_wth_dummies.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = score_train_data.iloc[:, 3:len(score_train_data.columns)-1]\n",
    "Y_train = score_train_data.iloc[:, len(score_train_data.columns)-1:]\n",
    "Y_train = np.ravel(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #Ordinary Least Squares\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Users/priscilleerulin/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #Ordinary Least Squares\n",
    "import numpy as np\n",
    "\n",
    "regressor = LinearRegression()\n",
    "# fit_intercept : boolean, optional, default True\n",
    "#    whether to calculate the intercept for this model. \n",
    "\n",
    "#normalize : boolean, optional, default False\n",
    "#    This parameter is ignored when fit_intercept is set to False. \n",
    "#    If True, the regressors X will be normalized before regression.\n",
    "\n",
    "#copy_X : boolean, optional, default True\n",
    "#    If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "# Train the model using the training sets\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'normalize':[True,False]} \n",
    "\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***GRIDSEARCH RESULTS***\n",
      "Best score: 0.171743 using {'normalize': False}\n",
      "0.171743 (0.001328) with: {'normalize': True}\n",
      "0.171743 (0.001328) with: {'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV 1/3; 1/27] START C=0.1, degree=2, epsilon=0.001, gamma=auto.................\n",
      "[CV 1/3; 1/27] END C=0.1, degree=2, epsilon=0.001, gamma=auto;, score=-0.354 total time=201.9min\n",
      "[CV 2/3; 1/27] START C=0.1, degree=2, epsilon=0.001, gamma=auto.................\n",
      "[CV 2/3; 1/27] END C=0.1, degree=2, epsilon=0.001, gamma=auto;, score=-0.356 total time=120.8min\n",
      "[CV 3/3; 1/27] START C=0.1, degree=2, epsilon=0.001, gamma=auto.................\n"
     ]
    }
   ],
   "source": [
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "regressor = SVR()\n",
    "parameters = {'C': [0.1, 1, 10],\n",
    "             'epsilon': [0.001, 0.01, 1],\n",
    "             'gamma':['auto'],\n",
    "             #'kernel': ['linear', 'poly','rbf'],\n",
    "             'degree': [2,3,5]\n",
    "             }\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3, verbose = 10,scoring ='neg_mean_absolute_error') #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_train\u001b[39m.\u001b[39;49mshape()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "Y_train.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
